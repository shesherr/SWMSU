{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120fde58-d21c-4491-bd22-40916632a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d5ed59-159c-4418-b263-70d94215084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b6825e-40ee-4f7c-a909-3babb4e94473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('StudentPerformanceFactors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e3b7c3-1959-44de-8036-2fcb561f1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6607 entries, 0 to 6606\n",
      "Data columns (total 20 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Hours_Studied               6607 non-null   int64 \n",
      " 1   Attendance                  6607 non-null   int64 \n",
      " 2   Parental_Involvement        6607 non-null   object\n",
      " 3   Access_to_Resources         6607 non-null   object\n",
      " 4   Extracurricular_Activities  6607 non-null   object\n",
      " 5   Sleep_Hours                 6607 non-null   int64 \n",
      " 6   Previous_Scores             6607 non-null   int64 \n",
      " 7   Motivation_Level            6607 non-null   object\n",
      " 8   Internet_Access             6607 non-null   object\n",
      " 9   Tutoring_Sessions           6607 non-null   int64 \n",
      " 10  Family_Income               6607 non-null   object\n",
      " 11  Teacher_Quality             6529 non-null   object\n",
      " 12  School_Type                 6607 non-null   object\n",
      " 13  Peer_Influence              6607 non-null   object\n",
      " 14  Physical_Activity           6607 non-null   int64 \n",
      " 15  Learning_Disabilities       6607 non-null   object\n",
      " 16  Parental_Education_Level    6517 non-null   object\n",
      " 17  Distance_from_Home          6540 non-null   object\n",
      " 18  Gender                      6607 non-null   object\n",
      " 19  Exam_Score                  6607 non-null   int64 \n",
      "dtypes: int64(7), object(13)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfafc4a-f262-4d73-9dc4-215ff8547b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132140"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8076823-ff12-4020-8694-00cb167354a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                  0\n",
       "Attendance                     0\n",
       "Parental_Involvement           0\n",
       "Access_to_Resources            0\n",
       "Extracurricular_Activities     0\n",
       "Sleep_Hours                    0\n",
       "Previous_Scores                0\n",
       "Motivation_Level               0\n",
       "Internet_Access                0\n",
       "Tutoring_Sessions              0\n",
       "Family_Income                  0\n",
       "Teacher_Quality               78\n",
       "School_Type                    0\n",
       "Peer_Influence                 0\n",
       "Physical_Activity              0\n",
       "Learning_Disabilities          0\n",
       "Parental_Education_Level      90\n",
       "Distance_from_Home            67\n",
       "Gender                         0\n",
       "Exam_Score                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a49e17-3f12-4a75-a792-85619ad97bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical: fill with mean\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in num_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical: fill with mode\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03dbb05-e906-4b9b-a50d-bc5f1cb6bed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hours_Studied                 0\n",
       "Attendance                    0\n",
       "Parental_Involvement          0\n",
       "Access_to_Resources           0\n",
       "Extracurricular_Activities    0\n",
       "Sleep_Hours                   0\n",
       "Previous_Scores               0\n",
       "Motivation_Level              0\n",
       "Internet_Access               0\n",
       "Tutoring_Sessions             0\n",
       "Family_Income                 0\n",
       "Teacher_Quality               0\n",
       "School_Type                   0\n",
       "Peer_Influence                0\n",
       "Physical_Activity             0\n",
       "Learning_Disabilities         0\n",
       "Parental_Education_Level      0\n",
       "Distance_from_Home            0\n",
       "Gender                        0\n",
       "Exam_Score                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d4fa42-66de-49ab-83bf-94013ba69c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9cecb67-a06f-4439-91ec-0cbaac98579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parental_Involvement: ['Low' 'Medium' 'High']\n",
      "Access_to_Resources: ['High' 'Medium' 'Low']\n",
      "Extracurricular_Activities: ['No' 'Yes']\n",
      "Motivation_Level: ['Low' 'Medium' 'High']\n",
      "Internet_Access: ['Yes' 'No']\n",
      "Family_Income: ['Low' 'Medium' 'High']\n",
      "Teacher_Quality: ['Medium' 'High' 'Low']\n",
      "School_Type: ['Public' 'Private']\n",
      "Peer_Influence: ['Positive' 'Negative' 'Neutral']\n",
      "Learning_Disabilities: ['No' 'Yes']\n",
      "Parental_Education_Level: ['High School' 'College' 'Postgraduate']\n",
      "Distance_from_Home: ['Near' 'Moderate' 'Far']\n",
      "Gender: ['Male' 'Female']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values of each categorical feature\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42aed8e4-a503-4b25-b69d-320a88861b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.copy()\n",
    "cat_cols = df_encoded.select_dtypes(include='object').columns.tolist()\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c148784b-45d5-489a-9ffe-473299ba0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('Exam_Score', axis=1)\n",
    "y = df_encoded['Exam_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac5f010-98b3-454f-84b8-e552864a72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6d572c-71d0-4ce4-85cb-0c50430391ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b70d5cd5-5c79-4dc3-af35-b16e4a636892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hours_Studied', 'Attendance', 'Parental_Involvement',\n",
       "       'Access_to_Resources', 'Extracurricular_Activities', 'Sleep_Hours',\n",
       "       'Previous_Scores', 'Motivation_Level', 'Internet_Access',\n",
       "       'Tutoring_Sessions', 'Family_Income', 'Teacher_Quality', 'School_Type',\n",
       "       'Peer_Influence', 'Physical_Activity', 'Learning_Disabilities',\n",
       "       'Parental_Education_Level', 'Distance_from_Home', 'Gender',\n",
       "       'Exam_Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8ddaeb-4ec6-435c-b5c0-06f521e1e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Confusion Matrix:\n",
      " [[ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  3  8  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  8  6 11  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  8 11 23 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  3 25 40  8  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6 36 47  5  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  3 18 76 49  2  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 29 81 32  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 41 57 44  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1 28 95 23  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 56 51 11  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  4 48 57  7  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 12 50 19  3  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1 21 32 16  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 13 19  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 13  0  3  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 12  0  2  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n",
      "\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          55       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         3\n",
      "          59       0.00      0.00      0.00         5\n",
      "          60       0.00      0.00      0.00        13\n",
      "          61       0.32      0.31      0.31        26\n",
      "          62       0.32      0.20      0.25        54\n",
      "          63       0.35      0.32      0.34        77\n",
      "          64       0.33      0.38      0.35        94\n",
      "          65       0.47      0.51      0.49       148\n",
      "          66       0.46      0.56      0.50       144\n",
      "          67       0.47      0.40      0.44       142\n",
      "          68       0.47      0.65      0.55       147\n",
      "          69       0.38      0.43      0.40       118\n",
      "          70       0.40      0.49      0.44       116\n",
      "          71       0.25      0.23      0.24        84\n",
      "          72       0.24      0.23      0.24        70\n",
      "          73       0.00      0.00      0.00        33\n",
      "          74       0.60      0.16      0.25        19\n",
      "          75       0.00      0.00      0.00        17\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40      1322\n",
      "   macro avg       0.17      0.17      0.17      1322\n",
      "weighted avg       0.38      0.40      0.38      1322\n",
      "\n",
      "\n",
      "‚úÖ Accuracy Score: 0.40468986384266264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Exam_Score\", axis=1)\n",
    "y = df[\"Exam_Score\"]\n",
    "\n",
    "# If the target is numeric but represents categories, convert it\n",
    "# Example: 90-100 = 'A', 80-89 = 'B', etc.\n",
    "# Uncomment and modify this block if needed\n",
    "# y = pd.cut(y, bins=[0, 59, 69, 79, 89, 100],\n",
    "#            labels=['F', 'D', 'C', 'B', 'A'])\n",
    "\n",
    "# Convert categorical features to dummy/one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM Classifier\n",
    "svm_clf = SVC(kernel='rbf')  # You can try other kernels like 'linear', 'poly'\n",
    "svm_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_clf.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "print(\"\\nüîç Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\n‚úÖ Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097e907c-77dd-427b-9c5a-830605d73c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "‚úÖ Best Parameters Found: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "\n",
      "üîç Confusion Matrix:\n",
      " [[0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          55       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.50      1.00      0.67         3\n",
      "          59       0.57      0.80      0.67         5\n",
      "          60       0.80      0.62      0.70        13\n",
      "          61       0.63      0.85      0.72        26\n",
      "          62       0.80      0.74      0.77        54\n",
      "          63       0.83      0.74      0.78        77\n",
      "          64       0.75      0.82      0.79        94\n",
      "          65       0.88      0.86      0.87       148\n",
      "          66       0.87      0.88      0.87       144\n",
      "          67       0.89      0.85      0.87       142\n",
      "          68       0.83      0.89      0.86       147\n",
      "          69       0.85      0.79      0.82       118\n",
      "          70       0.85      0.90      0.87       116\n",
      "          71       0.86      0.82      0.84        84\n",
      "          72       0.95      0.84      0.89        70\n",
      "          73       0.81      0.88      0.84        33\n",
      "          74       0.64      0.84      0.73        19\n",
      "          75       0.89      0.47      0.62        17\n",
      "          76       0.25      1.00      0.40         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          79       0.00      0.00      0.00         0\n",
      "          80       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         0\n",
      "          83       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         0\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         0\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83      1322\n",
      "   macro avg       0.40      0.43      0.40      1322\n",
      "weighted avg       0.83      0.83      0.83      1322\n",
      "\n",
      "\n",
      "üéØ Accuracy Score: 0.8282904689863843\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(\"Exam_Score\", axis=1)\n",
    "y = df[\"Exam_Score\"]\n",
    "\n",
    "# Convert numeric scores to categorical grades (if needed)\n",
    "# Modify bins and labels as per your dataset\n",
    "# y = pd.cut(y, bins=[0, 59, 69, 79, 89, 100], labels=['F', 'D', 'C', 'B', 'A'])\n",
    "\n",
    "# Encode categorical features\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "# Initialize SVM and GridSearch\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\n‚úÖ Best Parameters Found:\", grid.best_params_)\n",
    "\n",
    "# Predict using best model\n",
    "y_pred = grid.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüîç Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nüéØ Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3adc84-8c9d-4de7-8f46-3f4a6b305627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define a better parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 'scale'],\n",
    "    'kernel': ['rbf', 'poly', 'linear'],\n",
    "    'degree': [2, 3],  # for poly kernel\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold to better handle class imbalance\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Run GridSearch\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=cv, verbose=2, n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\n‚úÖ Best Parameters:\", grid.best_params_)\n",
    "\n",
    "# Predictions\n",
    "y_pred = grid.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüîç Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nüéØ Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c17ba3-d3e8-446d-91a9-e8491588e7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
